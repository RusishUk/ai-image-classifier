# ai_project/
# ‚îú‚îÄ‚îÄ model.py       # –ö–æ–¥ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
# ‚îú‚îÄ‚îÄ api.py         # REST API –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å –º–æ–¥–µ–ª—å—é
# ‚îú‚îÄ‚îÄ app.py         # Streamlit UI –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
# ‚îú‚îÄ‚îÄ requirements.txt  # –°–ø–∏—Å–æ–∫ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
# ‚îú‚îÄ‚îÄ README.md      # –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø—Ä–æ–µ–∫—Ç–∞
# ‚îú‚îÄ‚îÄ data/          # –ü–∞–ø–∫–∞ —Å –¥–∞—Ç–∞—Å–µ—Ç–æ–º
# ‚îú‚îÄ‚îÄ models/        # –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
# ‚îú‚îÄ‚îÄ utils/         # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏

# model.py (–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ PyTorch)
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import os

# –ü—Ä–æ—Å—Ç–∞—è CNN –º–æ–¥–µ–ª—å
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.relu = nn.ReLU()
        self.fc = nn.Linear(32 * 28 * 28, 10)

    def forward(self, x):
        x = self.relu(self.conv1(x))
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
transform = transforms.Compose([transforms.ToTensor()])
dataset = datasets.MNIST(root="data", train=True, download=True, transform=transform)
dataloader = DataLoader(dataset, batch_size=64, shuffle=True)

model = SimpleCNN()
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

for epoch in range(1):  # 1 —ç–ø–æ—Ö–∞ –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã
    for images, labels in dataloader:
        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
os.makedirs("models", exist_ok=True)
torch.save(model.state_dict(), "models/mnist_cnn.pth")

# api.py (REST API –Ω–∞ FastAPI)
from fastapi import FastAPI, UploadFile, File
import torch
from torchvision import transforms
from PIL import Image
import io

app = FastAPI()
model = SimpleCNN()
model.load_state_dict(torch.load("models/mnist_cnn.pth"))
model.eval()

transform = transforms.Compose([transforms.Grayscale(), transforms.ToTensor()])

@app.post("/predict")
async def predict(file: UploadFile = File(...)):
    image = Image.open(io.BytesIO(await file.read()))
    image = transform(image).unsqueeze(0)
    with torch.no_grad():
        output = model(image)
    prediction = torch.argmax(output, dim=1).item()
    return {"prediction": prediction}

# app.py (UI –Ω–∞ Streamlit)
import streamlit as st
import requests
from PIL import Image

st.title("AI Classifier UI")
uploaded_file = st.file_uploader("Upload an image", type=["png", "jpg", "jpeg"])

if uploaded_file is not None:
    image = Image.open(uploaded_file)
    st.image(image, caption="Uploaded Image", use_column_width=True)
    
    if st.button("Predict"):
        files = {"file": uploaded_file.getvalue()}
        response = requests.post("http://127.0.0.1:8000/predict", files=files)
        st.write("Prediction:", response.json()["prediction"])

# README.md (–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è)
# AI Image Classifier

## üìå –û–ø–∏—Å–∞–Ω–∏–µ
–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–µ–π—Ä–æ—Å–µ—Ç—å –Ω–∞ PyTorch –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.

## üöÄ –£—Å—Ç–∞–Ω–æ–≤–∫–∞
```sh
pip install -r requirements.txt
```

## üîß –ó–∞–ø—É—Å–∫
### 1. –ó–∞–ø—É—Å–∫ API
```sh
uvicorn api:app --reload
```
### 2. –ó–∞–ø—É—Å–∫ UI
```sh
streamlit run app.py

